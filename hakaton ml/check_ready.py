#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∫ –∑–∞–ø—É—Å–∫—É
"""
import sys
from pathlib import Path

def check_structure():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
    print("=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê")
    print("=" * 60)
    
    required_dirs = ['src', 'data/processed', 'models', 'output']
    all_ok = True
    
    for dir_path in required_dirs:
        path = Path(dir_path)
        if path.exists():
            print(f"  ‚úÖ {dir_path}/")
        else:
            print(f"  ‚ùå {dir_path}/ - –ù–ï –ù–ê–ô–î–ï–ù–ê")
            all_ok = False
    
    return all_ok

def check_files():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –§–ê–ô–õ–û–í")
    print("=" * 60)
    
    required_files = [
        'src/data_preparation.py',
        'src/baseline.py',
        'src/model_catboost.py',
        'src/inference.py',
        'requirements.txt'
    ]
    all_ok = True
    
    for file_path in required_files:
        path = Path(file_path)
        if path.exists():
            print(f"  ‚úÖ {file_path}")
        else:
            print(f"  ‚ùå {file_path} - –ù–ï –ù–ê–ô–î–ï–ù")
            all_ok = False
    
    return all_ok

def check_data():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–•")
    print("=" * 60)
    
    data_files = [
        'data/raw:/data.csv',
        'data/raw:/marking.csv',
        'data/raw:/sample_submission.csv'
    ]
    all_ok = True
    
    for data_file in data_files:
        path = Path(data_file)
        if path.exists():
            size = path.stat().st_size / 1024  # KB
            print(f"  ‚úÖ {data_file} ({size:.1f} KB)")
        else:
            alt_path = Path(data_file.replace('raw:', 'raw'))
            if alt_path.exists():
                size = alt_path.stat().st_size / 1024
                print(f"  ‚úÖ {data_file} (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å, {size:.1f} KB)")
            else:
                print(f"  ‚ùå {data_file} - –ù–ï –ù–ê–ô–î–ï–ù")
                all_ok = False
    
    return all_ok

def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô")
    print("=" * 60)
    
    dependencies = {
        'pandas': 'pandas',
        'numpy': 'numpy',
        'sklearn': 'scikit-learn',
        'catboost': 'catboost',
        'pyarrow': 'pyarrow',
        'joblib': 'joblib'
    }
    
    all_ok = True
    for module_name, package_name in dependencies.items():
        try:
            if module_name == 'sklearn':
                import sklearn
                version = sklearn.__version__
            else:
                mod = __import__(module_name)
                version = mod.__version__
            print(f"  ‚úÖ {package_name}: {version}")
        except ImportError:
            print(f"  ‚ùå {package_name} - –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
            all_ok = False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ LightGBM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    try:
        import lightgbm
        print(f"  ‚úÖ lightgbm: {lightgbm.__version__}")
    except ImportError:
        print(f"  ‚ö†Ô∏è  lightgbm - –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    except OSError:
        print(f"  ‚ö†Ô∏è  lightgbm - —Ç—Ä–µ–±—É–µ—Ç libomp (brew install libomp)")
    
    return all_ok

def check_processed_data():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
    print("=" * 60)
    
    processed_files = [
        'data/processed/train_final.parquet',
        'data/processed/test_final.parquet'
    ]
    
    all_exist = True
    for file_path in processed_files:
        path = Path(file_path)
        if path.exists():
            size = path.stat().st_size / 1024  # KB
            print(f"  ‚úÖ {file_path} ({size:.1f} KB)")
        else:
            print(f"  ‚ö†Ô∏è  {file_path} - –Ω–µ –Ω–∞–π–¥–µ–Ω (–∑–∞–ø—É—Å—Ç–∏—Ç–µ data_preparation.py)")
            all_exist = False
    
    return all_exist

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "=" * 60)
    print("üöÄ –ü–†–û–í–ï–†–ö–ê –ì–û–¢–û–í–ù–û–°–¢–ò –ü–†–û–ï–ö–¢–ê")
    print("=" * 60 + "\n")
    
    checks = [
        ("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞", check_structure),
        ("–§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞", check_files),
        ("–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", check_data),
        ("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏", check_dependencies),
        ("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", check_processed_data)
    ]
    
    results = {}
    for name, check_func in checks:
        results[name] = check_func()
    
    # –ò—Ç–æ–≥
    print("\n" + "=" * 60)
    print("–ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°")
    print("=" * 60)
    
    all_ok = True
    for name, result in results.items():
        status = "‚úÖ –ì–û–¢–û–í–û" if result else "‚ùå –¢–†–ï–ë–£–ï–¢ –í–ù–ò–ú–ê–ù–ò–Ø"
        print(f"  {name}: {status}")
        if not result and name != "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ":
            all_ok = False
    
    print("\n" + "=" * 60)
    if all_ok:
        print("‚úÖ –ü–†–û–ï–ö–¢ –ì–û–¢–û–í –ö –ó–ê–ü–£–°–ö–£!")
        print("\n–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
        print("  python3 src/data_preparation.py")
    else:
        print("‚ö†Ô∏è  –ï–°–¢–¨ –ü–†–û–ë–õ–ï–ú–´ - –ò–°–ü–†–ê–í–¨–¢–ï –ò–• –ü–ï–†–ï–î –ó–ê–ü–£–°–ö–û–ú")
    print("=" * 60 + "\n")

if __name__ == "__main__":
    main()

