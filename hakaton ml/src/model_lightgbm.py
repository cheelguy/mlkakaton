"""
LightGBM –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
"""
import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è LightGBM –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
from src.utils import log_info, load_dataframe, MODELS_DIR, setup_lightgbm_environment
setup_lightgbm_environment()

# –¢–µ–ø–µ—Ä—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º LightGBM
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError as e:
    log_info(f"‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
    LIGHTGBM_AVAILABLE = False
except OSError as e:
    log_info(f"‚ö†Ô∏è  LightGBM –Ω–µ –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è libomp): {e}")
    log_info("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ libomp: brew install libomp")
    LIGHTGBM_AVAILABLE = False

import joblib
from src.validation import evaluate_model, train_test_split_stratified

# –ö–ª–∞—Å—Å-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è LightGBM (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ –º–æ–¥—É–ª—è –¥–ª—è pickle)
class LightGBMWrapper:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è LightGBM –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å sklearn API"""
    def __init__(self, model):
        self.model = model
        self.feature_importances_ = model.feature_importance(importance_type='gain')
    
    def fit(self, X, y):
        """–î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å sklearn (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞)"""
        return self
    
    def predict_proba(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        pred = self.model.predict(X)
        return np.column_stack([1 - pred, pred])
    
    def predict(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤"""
        return (self.model.predict(X) > 0.5).astype(int)

def prepare_features_lightgbm(features_df, target_dict=None):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è LightGBM
    
    Args:
        features_df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        target_dict: —Å–ª–æ–≤–∞—Ä—å {student_id: target} –¥–ª—è train
    
    Returns:
        X: –ø—Ä–∏–∑–Ω–∞–∫–∏
        y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–µ—Å–ª–∏ target_dict –ø–µ—Ä–µ–¥–∞–Ω)
        feature_names: –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        cat_features: –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ-–ø—Ä–∏–∑–Ω–∞–∫–∏
    exclude_cols = ['student_id', '–§–∞–∫—É–ª—å—Ç–µ—Ç', '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–≥–æ–¥ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è']
    feature_cols = [col for col in features_df.columns if col not in exclude_cols]
    
    X = features_df[feature_cols].fillna(0)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    cat_features = []
    for col in feature_cols:
        if 'encoded' in col.lower() or col in ['faculty_encoded', 'direction_encoded']:
            cat_features.append(col)
    
    if target_dict is not None:
        y = features_df['student_id'].map(target_dict).fillna(0).astype(int)
        return X, y, feature_cols, cat_features
    else:
        return X, None, feature_cols, cat_features

def train_lightgbm(X_train, y_train, X_val=None, y_val=None, cat_features=None):
    """
    –û–±—É—á–µ–Ω–∏–µ LightGBM –º–æ–¥–µ–ª–∏
    
    Args:
        X_train: –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        y_train: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        X_val: –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        y_val: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        cat_features: –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    Returns:
        model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        metrics: –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
    """
    if not LIGHTGBM_AVAILABLE:
        raise ImportError("LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ libomp: brew install libomp")
    
    log_info("\n" + "=" * 60)
    log_info("–û–ë–£–ß–ï–ù–ò–ï LIGHTGBM –ú–û–î–ï–õ–ò")
    log_info("=" * 60)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'random_state': 42
    }
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LightGBM
    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features if cat_features else None)
    
    if X_val is not None and y_val is not None:
        val_data = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_features if cat_features else None, reference=train_data)
        log_info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π...")
        model = lgb.train(
            params,
            train_data,
            num_boost_round=1000,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'val'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=100),
                lgb.log_evaluation(period=100)
            ]
        )
    else:
        log_info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        model = lgb.train(
            params,
            train_data,
            num_boost_round=1000,
            callbacks=[lgb.log_evaluation(period=100)]
        )
    
    # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å sklearn API
    wrapped_model = LightGBMWrapper(model)
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    metrics = evaluate_model(wrapped_model, X_train, y_train, X_val, y_val, cv=5)
    
    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    log_info("\nüìä –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': wrapped_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    for i, row in feature_importance.head(10).iterrows():
        log_info(f"  {row['feature']}: {row['importance']:.4f}")
    
    metrics['feature_importance'] = feature_importance.to_dict('records')
    
    return wrapped_model, metrics

if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LightGBM
    if not LIGHTGBM_AVAILABLE:
        log_info("‚ùå LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
        log_info("   –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ libomp –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: brew install libomp")
        log_info("   –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ CatBoost –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É: python src/model_catboost.py")
        sys.exit(1)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    log_info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (–µ—Å–ª–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ù–∏–∫–∏—Ç–æ–π)
    try:
        train_final = load_dataframe("train_final.parquet")
        log_info("  –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π train –¥–∞—Ç–∞—Å–µ—Ç (–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ù–∏–∫–∏—Ç–æ–π)")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        X_train = train_final.drop(['student_id', 'target'], axis=1)
        y_train = train_final['target']
        feature_cols = list(X_train.columns)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        cat_features = []
        for col in feature_cols:
            if 'encoded' in col.lower() or col in ['faculty_encoded', 'direction_encoded']:
                cat_features.append(col)
        
    except FileNotFoundError:
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±
        log_info("  –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±...")
        features_df = load_dataframe("features.parquet")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ target –¥–ª—è train
        train_target = load_dataframe("train_target.parquet")
        target_dict = dict(zip(train_target['–ò–î'], train_target['target']))
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        train_students = set(train_target['–ò–î'].unique())
        train_features = features_df[features_df['student_id'].isin(train_students)].copy()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_train, y_train, feature_cols, cat_features = prepare_features_lightgbm(train_features, target_dict)
    
    log_info(f"  Train —Ä–∞–∑–º–µ—Ä: {len(X_train):,} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    log_info(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    log_info(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(cat_features)}")
    log_info(f"  –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {y_train.value_counts().to_dict()}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
    X_train_split, X_val, y_train_split, y_val = train_test_split_stratified(
        X_train, y_train, test_size=0.2, random_state=42
    )
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    try:
        model, metrics = train_lightgbm(X_train_split, y_train_split, X_val, y_val, cat_features)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_path = MODELS_DIR / "lightgbm_model.pkl"
        joblib.dump(model, model_path)
        log_info(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        import json
        model_info = {
            'feature_names': feature_cols,
            'cat_features': cat_features,
            'metrics': metrics
        }
        with open(Path(__file__).parent.parent / "output" / "lightgbm_info.json", 'w') as f:
            json.dump(model_info, f, indent=2, default=str)
        
        log_info("\n‚úÖ LightGBM –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    except Exception as e:
        log_info(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LightGBM: {e}")
        log_info("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ libomp —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: brew install libomp")
        sys.exit(1)

